set(from utils import timer);//
set(from utils.functions import MovingAverage, make_net);//
set(torch.cuda.current_device());//
set(use_jit = torch.cuda.device_count() <= 1);//
set(if not use_jit:);//
output(	print("Multiple GPUs detected! Turning off JIT."));//
set();//
#--------------------------------- if not use_jit: if
set(ScriptModuleWrapper = torch.jit.ScriptModule if use_jit else nn.Module);//
set(script_method_wrapper = torch.jit.script_method if use_jit else lambda fn, _rcn=None: fn);//
input(class Concat(nn.Module):);//
input(class Concat(nn.Module):);//
input(	def __init__(self, nets, extra_params):);//
set(		super().__init__());//
set(		self.nets = nn.ModuleList(nets));//
set(		self.extra_params = extra_params);//
input(	def forward(self, x):);//
#--------------------------------- 	def __init__(self, nets, extra_params):
end(		return torch.cat([net(x) for net in self.nets], dim=1, **self.extra_params));//
input(class PredictionModule(nn.Module):);//
#--------------------------------- class Concat(nn.Module):
input(class PredictionModule(nn.Module):);//
#--------------------------------- class Concat(nn.Module):
set(	""");//
set(	The (c) prediction module adapted from DSSD:);//
set(	https://arxiv.org/pdf/1701.06659.pdf);//
set(	Note that this is slightly different to the module in the paper);//
set(	because the Bottleneck block actually has a 3x3 convolution in);//
set(	the middle instead of a 1x1 convolution. Though, I really can't);//
set(	be arsed to implement it myself, and, who knows, this might be);//
set(	better.);//
set(	Args:);//
set(	- in_channels:   The input feature size.);//
set(	- out_channels:  The output feature size (must be a multiple of 4).);//
set(	- aspect_ratios: A list of lists of priorbox aspect ratios (one list per scale).);//
set(	- scales:		A list of priorbox scales relative to this layer's convsize.);//
set(	For instance: If this layer has convouts of size 30x30 for);//
#--------------------------------- class PredictionModule(nn.Module):
set(	an image of size 600x600, the 'default' (scale);//
set(	of 1) for this layer would produce bounding);//
set(	boxes with an area of 20x20px. If the scale is);//
set(	.5 on the other hand, this layer would consider);//
set(	bounding boxes with area 10x10px, etc.);//
set(	- parent:		If parent is a PredictionModule, this module will use all the layers);//
set(	from parent instead of from this module.);//
set(	""");//
input(	def __init__();//
set(		self,);//
set(		in_channels,);//
set(		out_channels=1024,);//
set(		aspect_ratios=[[1]],);//
set(		scales=[1],);//
set(		parent=None,);//
set(		index=0,);//
set(	):);//
#--------------------------------- 	def __init__(
set(		super().__init__());//
set(		self.num_classes = cfg.num_classes);//
set(		self.mask_dim = cfg.mask_dim);//
set(		self.num_priors = sum(len(x) * len(scales) for x in aspect_ratios));//
set(		self.parent = [parent]);//
set(		self.index = index);//
set(		self.num_heads = cfg.num_heads);//
branch(		if ();//
path();
set(			cfg.mask_proto_split_prototypes_by_head);//
set(			and cfg.mask_type == mask_type.lincomb);//
set(		):);//
#--------------------------------- 		if (
set(			self.mask_dim = self.mask_dim // self.num_heads);//
branch(		if cfg.mask_proto_prototypes_as_features:);//
path();
set(			in_channels += self.mask_dim);//
branch(		if parent is None:);//
#--------------------------------- 		if cfg.mask_proto_prototypes_as_features:
path();
branch(			if cfg.extra_head_net is None:);//
path();
set(				out_channels = in_channels);//
path(			else:);//
#--------------------------------- 			if cfg.extra_head_net is None:
set(				self.upfeature, out_channels = make_net(in_channels, cfg.extra_head_net));//
branch(			if cfg.use_prediction_module:);//
path();
set(				self.block = Bottleneck(out_channels, out_channels // 4));//
set(				self.conv = nn.Conv2d();//
set(					out_channels, out_channels, kernel_size=1, bias=True);//
set(				));//
#--------------------------------- 			if cfg.use_prediction_module:
set(				self.bn = nn.BatchNorm2d(out_channels));//
set(			self.bbox_layer = nn.Conv2d();//
set(				out_channels, self.num_priors * 4, **cfg.head_layer_params);//
set(			));//
set(			self.conf_layer = nn.Conv2d();//
set(				out_channels,);//
set(				self.num_priors * self.num_classes,);//
set(				**cfg.head_layer_params);//
set(			));//
set(			self.mask_layer = nn.Conv2d();//
set(				out_channels, self.num_priors * self.mask_dim, **cfg.head_layer_params);//
set(			));//
branch(			if cfg.use_mask_scoring:);//
path();
set(				self.score_layer = nn.Conv2d();//
set(					out_channels, self.num_priors, **cfg.head_layer_params);//
set(				));//
#--------------------------------- 			if cfg.use_mask_scoring:
branch(			if cfg.use_instance_coeff:);//
path();
set(				self.inst_layer = nn.Conv2d();//
set(					out_channels,);//
set(					self.num_priors * cfg.num_instance_coeffs,);//
set(					**cfg.head_layer_params);//
set(				));//
#--------------------------------- 			if cfg.use_instance_coeff:
input(			def make_extra(num_layers):);//
branch(				if num_layers == 0:);//
path();
end(					return lambda x: x);//
path(				else:);//
#--------------------------------- 				if num_layers == 0:
end(					return nn.Sequential();//
set(						*sum();//
set(							[);//
set(								[);//
set(									nn.Conv2d();//
set(										out_channels,);//
set(										out_channels,);//
set(										kernel_size=3,);//
set(										padding=1,);//
set(									),);//
set(									nn.ReLU(inplace=True),);//
set(								]);//
loop(								for _ in range(num_layers));//
set(							],);//
set(							[],);//
set(						));//
set(					));//
set(			self.bbox_extra, self.conf_extra, self.mask_extra = [);//
set(				make_extra(x) for x in cfg.extra_layers);//
set(			]);//
branch(			if cfg.mask_type == mask_type.lincomb and cfg.mask_proto_coeff_gate:);//
path();
set(				self.gate_layer = nn.Conv2d();//
set(					out_channels,);//
set(					self.num_priors * self.mask_dim,);//
set(					kernel_size=3,);//
#--------------------------------- 			if cfg.mask_type == mask_type.lincomb and cfg.mask_proto_coeff_gate:
set(					padding=1,);//
set(				));//
set(		self.aspect_ratios = aspect_ratios);//
set(		self.scales = scales);//
set(		self.priors = None);//
set(		self.last_conv_size = None);//
set(		self.last_img_size = None  );//-------------------------DONE
set(prior_cache = defaultdict(lambda: None));//
;INSECTA EMBEDDED SESSION INFORMATION
; 255 16777215 65280 16777088 16711680 255 8388608 0 255 255 65535 65280 4210688 
test.py.py   #"""  #"""  
; notepad++.exe 
;INSECTA EMBEDDED ALTSESSION INFORMATION
; 262 123 765 1694 0 170   379   4294966903    python.key  0